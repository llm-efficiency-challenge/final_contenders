{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/xiayu/.cache/huggingface/datasets/databricks___json/databricks--databricks-dolly-15k-7427aa6e57c34282/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c43975bc114ee38ea27501d94aaf90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. get dolly data\n",
    "dolly = load_dataset(\"databricks/databricks-dolly-15k\")\n",
    "\n",
    "random.seed(1)\n",
    "random_dolly = random.sample(range(len(dolly['train'])),8000)\n",
    "select_dolly = []\n",
    "prefix = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "for num in random_dolly:\n",
    "    nd = {}\n",
    "    prompt = dolly['train'][num]['instruction']+'\\n'+dolly['train'][num]['context']\n",
    "    nd[\"instruction\"] = prefix+f\"### Instruction:\\n{prompt}\\n\\n### Response:\\n\"\n",
    "    nd[\"input\"] = \"\"\n",
    "    nd[\"output\"] = dolly['train'][num]['response']\n",
    "    select_dolly.append(nd)\n",
    "\n",
    "with open(f'datas/dolly_{len(random_dolly)}.json', 'w') as output_file:\n",
    "    json.dump(select_dolly, output_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/Users/xiayu/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e08e50289f6406ea21a9c74ed6119e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. get CNN\n",
    "cnn = load_dataset(\"cnn_dailymail\",\"3.0.0\")\n",
    "\n",
    "random.seed(7)\n",
    "random_cnn = random.sample(range(len(cnn['train'])),3000)\n",
    "select_cnn = []\n",
    "prefix = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "\n",
    "for num in random_cnn:\n",
    "    nd = {}\n",
    "    highlights=cnn['train'][num]['highlights'].split(\"\\n\")\n",
    "    sens = len(highlights)\n",
    "    highlights = \" \".join(highlights)\n",
    "    prompt = \"###\\nArticle: \"+cnn['train'][num]['article']+f\"\\n\\nSummarize the above article in {str(sens)} sentences.\\n\"\n",
    "    nd[\"instruction\"] = prompt  \n",
    "    nd[\"input\"] = \"\"\n",
    "    nd[\"output\"] = highlights+\"\\n\\n\"\n",
    "    select_cnn.append(nd)\n",
    "\n",
    "with open(f'datas/cnn_{len(random_cnn)}_direct.json', 'w') as output_file:\n",
    "    json.dump(select_cnn, output_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
