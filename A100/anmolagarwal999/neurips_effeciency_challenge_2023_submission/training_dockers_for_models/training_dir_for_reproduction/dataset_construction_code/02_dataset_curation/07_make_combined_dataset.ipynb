{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db5a1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e74757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_use = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abdfe922",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../../data/training_datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecff1396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENTIRE_cnn_valid_dataset.json',\n",
       " 'combined_valid_dataset.json',\n",
       " 'cnn_test_dataset.json',\n",
       " 'ENTIRE_cnn_train_dataset.json',\n",
       " 'gsm_test_dataset.json',\n",
       " 'cnn_valid_dataset.json',\n",
       " 'tqa_valid_dataset.json',\n",
       " 'mathqa_train_dataset.json',\n",
       " 'stem_bigbench_valid_dataset.json',\n",
       " 'combined_train_dataset.json',\n",
       " 'bbq_train_dataset.json',\n",
       " 'stem_bigbench_test_dataset.json',\n",
       " 'mathqa_test_dataset.json',\n",
       " 'bigbench_valid_dataset.json',\n",
       " 'bigbench_train_dataset.json',\n",
       " 'mathqa_valid_dataset.json',\n",
       " 'mmlu_train_dataset.json',\n",
       " 'gsm_valid_dataset.json',\n",
       " 'mmlu_valid_dataset.json',\n",
       " 'cnn_train_dataset.json',\n",
       " 'combined_test_dataset.json',\n",
       " 'bigbench_test_dataset.json',\n",
       " 'mmlu_test_dataset.json',\n",
       " 'gsm_train_dataset.json',\n",
       " 'ENTIRE_cnn_test_dataset.json',\n",
       " 'tqa_test_dataset.json',\n",
       " 'bbq_test_dataset.json',\n",
       " 'tqa_train_dataset.json',\n",
       " 'stem_bigbench_train_dataset.json',\n",
       " 'bbq_valid_dataset.json']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = list(os.listdir(BASE_DIR))\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab93578",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = list(filter(lambda x:split_use in x, all_files))\n",
    "all_files = list(filter(lambda x:\"cnn\" not in x, all_files))\n",
    "all_files = list(filter(lambda x:\"combined\" not in x, all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02b5ad17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mathqa_train_dataset.json',\n",
       " 'bbq_train_dataset.json',\n",
       " 'bigbench_train_dataset.json',\n",
       " 'mmlu_train_dataset.json',\n",
       " 'gsm_train_dataset.json',\n",
       " 'tqa_train_dataset.json',\n",
       " 'stem_bigbench_train_dataset.json']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf8d9ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/training_datasets/mathqa_train_dataset.json\n",
      "Number of elements is:  680\n",
      "#####\n",
      "../../data/training_datasets/bbq_train_dataset.json\n",
      "Number of elements is:  1600\n",
      "#####\n",
      "../../data/training_datasets/bigbench_train_dataset.json\n",
      "Number of elements is:  1506\n",
      "#####\n",
      "../../data/training_datasets/mmlu_train_dataset.json\n",
      "Number of elements is:  824\n",
      "#####\n",
      "../../data/training_datasets/gsm_train_dataset.json\n",
      "Number of elements is:  500\n",
      "#####\n",
      "../../data/training_datasets/tqa_train_dataset.json\n",
      "Number of elements is:  163\n",
      "#####\n",
      "../../data/training_datasets/stem_bigbench_train_dataset.json\n",
      "Number of elements is:  1275\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "whole_arr = []\n",
    "for curr_file in all_files:\n",
    "    file_path = os.path.join(BASE_DIR, curr_file)\n",
    "    print(file_path)\n",
    "    with open(file_path, 'r') as fd:\n",
    "        df = json.load(fd)\n",
    "        df = df[:1600]\n",
    "    whole_arr.extend(df)\n",
    "    print(\"Number of elements is: \", len(df))\n",
    "    print(\"#####\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2962628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_id = -1\n",
    "for curr_elem in whole_arr:\n",
    "    combined_id+=1\n",
    "    curr_elem['combined_id'] = combined_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c45b1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"../../data/training_datasets/combined_{split_use}_dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8351605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/training_datasets/combined_train_dataset.json'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8119facb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(whole_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee62e9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mmlu_id': 12280,\n",
       " 'group_id': 4165,\n",
       " 'category': 'moral_scenarios',\n",
       " 'perturb_type': 'dialect_obj',\n",
       " 'split_used': 'train',\n",
       " 'instruction': 'The following are multiple choice questions (with answers) about moral scenarios.\\n\\nQuestion: For which of dese two scenarios does da main character (who uses I/me/mah) do sumin clearly morally wrong, according to ordinary moral standards in da US as of 2020? Scenario 1 | I bought an old pick-up truck fir work. Scenario 2 | I looked up at da gorgeous waterfall and threw a rock at it.\\nA. Wrong, Wrong\\nB. Wrong, Not wrong\\nC. Not wrong, Wrong\\nD. Not wrong, Not wrong\\nAnswer:',\n",
       " 'output': 'D',\n",
       " 'combined_id': 4506}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_arr[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9000d668",
   "metadata": {},
   "source": [
    "with open(save_path, 'w') as fd:\n",
    "    json.dump(whole_arr, fd, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa66a8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6548"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_arr)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b10029a0",
   "metadata": {},
   "source": [
    "!ls /home/anmol/deego_mounted_dump/nips_challenge_experiments/training_datasets/training_datasets/combined_train_dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adea8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a1db043",
   "metadata": {},
   "source": [
    "path = \"/home/anmol/deego_mounted_dump/nips_challenge_experiments/training_datasets/training_datasets/combined_train_dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3704f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as fd:\n",
    "    df  = json.load(fd)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0deeddf4",
   "metadata": {},
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ba1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wizard_coder_kernel",
   "language": "python",
   "name": "wizard_coder_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
